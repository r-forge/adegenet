\documentclass{article}
% \VignettePackage{dapc}
% \VignetteIndexEntry{An introduction to Discriminant Analysis of Principal Components (DAPC)}

\usepackage{graphicx}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}
\usepackage{array}
\usepackage{color}

\usepackage[utf8]{inputenc} % for UTF-8/single quotes from sQuote()


% for bold symbols in mathmode
\usepackage{bm}

\newcommand{\R}{\mathbb{R}}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\m}[1]{\mathbf{#1}}



\newcommand{\code}[1]{{{\tt #1}}}
\title{An introduction to Discriminant Analysis of Principal Components (DAPC)}
\author{Thibaut Jombart}
\date{\today}




\sloppy
\hyphenpenalty 10000


\begin{document}



\definecolor{Soutput}{rgb}{0,0,0.56}
\definecolor{Sinput}{rgb}{0.56,0,0}
\DefineVerbatimEnvironment{Sinput}{Verbatim}
{formatcom={\color{Sinput}},fontsize=\footnotesize, baselinestretch=0.75}
\DefineVerbatimEnvironment{Soutput}{Verbatim}
{formatcom={\color{Soutput}},fontsize=\footnotesize, baselinestretch=0.75}

\color{black}

\maketitle

\begin{abstract}
  This vignette provides a tutorial for applying the Discriminant Analysis of Principal Components
  (DAPC \cite{tjart19}) using the \textit{adegenet} package \cite{tjart05} for the R software
  \cite{np145}. This methods aims to identify and describe genetic clusters, although it can in fact
  be applied to any quantitative data. We illustrate how to use \code{find.clusters} to identify
  clusters, and \code{dapc} to describe the relationships between these clusters. More advanced
  topics are then introduced, such as the stability of DAPC results and supplementary individuals.
\end{abstract}


\newpage
\tableofcontents


\newpage
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{Rationale}
%%%%%%%%%%%%%%%%

Investigating genetic diversity using multivariate approaches relies on finding synthetic variables
built as linear combinations of alleles (i.e. $a_1 \mbox{allele}_1 + a_2 \mbox{allele}_2 + ... $)
and which reflect as well as possible the genetic variation between the studied individuals.
However, most of the time we are not only interested in the diversity amongst individuals, but
also and possibly more in the diversity between groups of individuals.
Typically, one will be analysing individual data to identify populations, or more largely genetic
clusters, and then describe these clusters.

A problem occuring in traditional methods is focussing on the entire variation.
Genetic data can be described using a standard multivariate ANOVA model:
$$
\mbox{total variance} = \mbox{(variance between groups)} + \mbox{(variance within groups)}
$$
or more simply, denoting $\m{X}$ the data matrix:
$$
VAR(\m{X}) = B(\m{X}) + W(\m{X})
$$

That is, usual approaches such as Principal Component Analysis (PCA) or Principal Coordinate
Analysis (PCoA / MDS) focus on $VAR(\m{X})$. That is, they only describe the global diversity,
possibly overlooking differences between groups. On the contrary, DAPC optimizes $B(\m{X})$ while
minimizing $W(\m{X})$: it seeks synthetic variables, the \textit{discriminant functions}, which show
differences between groups as best as possible while minimizing variation within clusters.










%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Identifying clusters using \code{find.clusters}}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%
\subsection{Rationale}
%%%%%%%%%%%%%%%%
DAPC in itself requires prior groups to be defined. However, groups are often unknown or uncertain,
and there is a need for identifying genetic clusters before describing them. This can be achieved by
using $k$-means, a clustering algorithm which finds $k$ groups maximizing the variation between
groups, $B(\m{X})$. To identify the optimal number of clusters, $k$-means is run sequentially with
increasing values of $k$, and different clustering solutions are compared using Bayesian Information
Criterion (BIC). Ideally, the optimal clustering solution should correspond to the lowest BIC. In
practice, the 'best' BIC is often indicated by an elbow in the curve of BIC values as a function of
$k$.

While $k$-means could be performed on the raw data, we prefer running the algorithm after
transforming the data using PCA. This transformation has the major advantage of reducing the
number of variables so as to speed up the clustering algorithm. Note this does not imply a loss of
information and different results from the raw data, since one can retain all the principal
components (PCs) and therefore all the variation in the original data. However, in practice, a reduced
number of PCs is often sufficient to identify the existing clusters, while allowing the clusters to
be obtained essentially instantaneously.


%%%%%%%%%%%%%%%%
\subsection{In practice}
%%%%%%%%%%%%%%%%

Identification of the clusters is achieved by \code{find.clusters}. This function first transforms
the data using PCA, asking the users to specify the number of retained PCs interactively unless the
argument \code{n.pca} is provided. Then, it runs $k$-means algorithm (function \code{kmeans} from
the \textit{stats} package) with increasing values of $k$, unless the argument  \code{n.clust} is
provided. See \code{?find.clusters} for other arguments.

\code{find.clusters} is a generic function with methods for \texttt{data.frame}, and objects with
the class \texttt{genind} (usual genetic markers) and \texttt{genlight} (genome wide SNP data).
Here, we illustrate its use using a toy dataset simulated in \cite{tjart19}, \texttt{dapcIllus}:
<<>>=
library(adegenet)
data(dapcIllus)
class(dapcIllus)
names(dapcIllus)
@

\texttt{dapcIllus} is a list containing four datasets; we shall only use the first one:
<<>>=
x <- dapcIllus$a
x
@
\texttt{x} is a dataset of 600 individuals simulated under an 6 island model for 30 microsatellite markers.
We use \code{find.clusters} to identify clusters, although true clusters are, in this case, known.
We specify that we want to evaluate up to $k=40$ groups (\texttt{max.n.clust=40}):
<<eval=FALSE>>=
grp <- find.clusters(x, max.n.clust=40)
@

\begin{center}
  \includegraphics[width=.7\textwidth]{figs/findclust-pca.pdf}
\end{center}

\noindent
The function displays a graph of cumulated variance explained by the eigenvalues of the PCA.
Apart from computational time, there is no reason for keeping a small number of components; here, we
keep all the information, specifying to retain 200 PCs (there are actually less PCs ---around 110---, so all of them
are kept).

Then, the function displays a graph of BIC values for increasing values of $k$:
\begin{center}
  \includegraphics[width=.7\textwidth]{figs/findclust-bic.pdf}
\end{center}

\noindent This graph shows a clear decrease of BIC until $k=6$ clusters, after which BIC increases.
In this case, the elbow in the curve also matches the smallest BIC, and clearly indicates 6 clusters
should be retained. In practice, the choice is often trickier to make.
\\


%%%%%%%%%%%%%%%%
\subsection{How many clusters are there really in the data?}
%%%%%%%%%%%%%%%%

Although the most frequently asked when trying to find clusters in genetic data, this question is
equally often meaningless. Clustering algorithms help making a caricature of a complex reality,
which is most of the time far from following known population genetics models. Therefore, we are
rarely looking for actual panmictic populations from which the individuals have been drawn. Genetic
clusters can be biologically meaningful structures and reflect interesting biological processes, but
they are still models.

A slightly different but probably more relevant question would be: "How many clusters are useful to
describe the data?''. A fundamental point in this question is that clusters are merely tools used to
summarise and understand the data. There is no longer a "true $k$", but some values of $k$ are
better, more efficient summaries of the data than others.
For instance, in the following case:
\begin{center}
  \includegraphics[width=.7\textwidth]{figs/findclust-bic.pdf}
\end{center}

\noindent , the concept of "true $k$" is fairly hypothetical. This does not mean that clutering
algorithms should necessarily be discarded, but surely the reality is more complex than a few
clear-cut, isolated populations. What the BIC decrease says is that 10-20 clusters would provide useful
summaries of the data. The actual number retained is merely a question of personnal taste.




%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Describing clusters using \code{dapc}}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%
\subsection{Rationale}
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{In practice}
%%%%%%%%%%%%%%%%








%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Customizing graphics}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{DAPC scatterplots}
%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%
\subsection{Group memberships}
%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Ensuring stability of DAPC results}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{Why DAPC results could vary?}
%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%
\subsection{Using the $a$-score}
%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\section{Using supplementary individuals}
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%
\subsection{Rationale}
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{Predicting group membership}
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%
\subsection{Representing supplementary individuals}
%%%%%%%%%%%%%%%%


\end{document}
